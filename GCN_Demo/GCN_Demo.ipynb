{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN_Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A_rIyeEURkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#g=nx.karate_club_graph()\n",
        "edge_index1 = [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 10], [0, 11], [0, 12], [0, 13], [0, 17], [0, 19], [0, 21], [0, 31], [1, 2], [1, 3], [1, 7], [1, 13], [1, 17], [1, 19], [1, 21], [1, 30], [2, 3], [2, 7], [2, 8], [2, 9], [2, 13], [2, 27], [2, 28], [2, 32], [3, 7], [3, 12], [3, 13], [4, 6], [4, 10], [5, 6], [5, 10], [5, 16], [6, 16], [8, 30], [8, 32], [8, 33], [9, 33], [13, 33], [14, 32], [14, 33], [15, 32], [15, 33], [18, 32], [18, 33], [19, 33], [20, 32], [20, 33], [22, 32], [22, 33], [23, 25], [23, 27], [23, 29], [23, 32], [23, 33], [24, 25], [24, 27], [24, 31], [25, 31], [26, 29], [26, 33], [27, 33], [28, 31], [28, 33], [29, 32], [29, 33], [30, 32], [30, 33], [31, 32], [31, 33], [32, 33]]\n",
        "node_labels1 = [0,0,0,0,0,0,0,0,0, 1, 0,0,0,0, 1,1, 0,0, 1,0, 1,0, 1,1,1,1,1,1,1,1,1,1,1,1]\n",
        "#node_labels = list(map(lambda node : 'r' if node == 0 else 'g', node_labels))\n",
        "output1 = [[-7.0196e-01, -6.8441e-01],\n",
        "        [-7.1878e-01, -6.6815e-01],\n",
        "        [-7.2843e-01, -6.5906e-01],\n",
        "        [-7.2013e-01, -6.6687e-01],\n",
        "        [-6.9284e-01, -6.9346e-01],\n",
        "        [-7.1604e-01, -6.7077e-01],\n",
        "        [-2.7555e-01, -1.4236e+00],\n",
        "        [-5.6927e-03, -5.1714e+00],\n",
        "        [-7.2458e-01, -6.6267e-01],\n",
        "        [-7.4164e-01, -6.4690e-01],\n",
        "        [-1.4926e-03, -6.5080e+00],\n",
        "        [-6.5135e-02, -2.7637e+00],\n",
        "        [-1.6991e-02, -4.0835e+00],\n",
        "        [-4.4208e-01, -1.0292e+00],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-5.5075e-05, -9.8074e+00],\n",
        "        [-3.8752e-02, -3.2699e+00],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-6.5634e-01, -7.3136e-01],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-3.8752e-02, -3.2699e+00],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-7.2063e-01, -6.6640e-01],\n",
        "        [-7.2472e-01, -6.6254e-01],\n",
        "        [-8.5906e-01, -5.5089e-01],\n",
        "        [-7.6425e-01, -6.2676e-01],\n",
        "        [-8.7084e-01, -5.4231e-01],\n",
        "        [-7.3216e-01, -6.5560e-01],\n",
        "        [-9.5935e-01, -4.8312e-01],\n",
        "        [-7.0129e-01, -6.8507e-01],\n",
        "        [-8.2021e-01, -5.8042e-01],\n",
        "        [-2.6129e+00, -7.6149e-02],\n",
        "        [-1.4436e+01, -9.5367e-07]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnFSSfL7UIKK",
        "colab_type": "code",
        "outputId": "039892b3-a034-41ff-c980-ab3ff74abd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "#coding=utf-8\n",
        "#https://networkx.github.io/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html#networkx.drawing.nx_pylab.draw_networkx\n",
        "#MSC means Multiple Spectral Clustering\n",
        " \n",
        "import numpy as np\n",
        " \n",
        "import scipy as sp\n",
        " \n",
        "import scipy.linalg as linalg\n",
        " \n",
        "import networkx as nx\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw_graph_from_nodelist(edge_index, node_labels, output = 'defult', save_name = 'defult',show_content = 'none'):\n",
        "\n",
        "    g = nx.from_edgelist(edge_index) \n",
        "    \n",
        "    plt.figure(figsize=(8,8))\n",
        "    if(output == 'defult'):\n",
        "        pos=nx.spring_layout(g)\n",
        "    else:\n",
        "        pos = {}\n",
        "        for i in range(len(node_labels)):\n",
        "            pos[i] = np.array(output[i])\n",
        "        \n",
        "    nx.draw_networkx_edges(g,pos,alpha=0.4)\n",
        "\n",
        "    nx.draw_networkx_nodes(g,pos,nodelist=list(range(0,len(node_labels))),node_color= list(node_labels))\n",
        "\n",
        "    nx.draw_networkx_labels(g,pos,font_size=10,font_family='sans-serif')\n",
        "\n",
        "    plt.axis('off')\n",
        "    xy = np.mean(output, axis = 0)\n",
        "    print(xy)\n",
        "    if(show_content != 'none'):\n",
        "        plt.text(xy[0]*4, xy[-1], show_content,fontsize=15)\n",
        "    if(save_name == 'defult'):\n",
        "        plt.title(\"karate_club GCN \")\n",
        "        plt.savefig(\"GCN——karate_club-result.png\")\n",
        "        \n",
        "    else:\n",
        "        plt.title(\"karate_club GCN \" + str(save_name))\n",
        "        plt.savefig(str(save_name)+'.png')\n",
        "%matplotlib inline\n",
        "draw_graph_from_nodelist(edge_index1, node_labels1, output1,111, show_content = 'acc {:.3f}'.format(444.31233))     "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.03846766 -1.53156794]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAHRCAYAAADnk4nDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTEmSMvwDbXR+Q+KUVM4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7FUrGIS5w9U",
        "colab_type": "code",
        "outputId": "6ff7a66e-4668-4f03-dbdb-41ea690e82ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# load data\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "KarateClubGraph = nx.karate_club_graph()\n",
        "KarateClubGraph_edge_indx = list(map(lambda edge: list(edge),list(KarateClubGraph.edges)))\n",
        "print(KarateClubGraph_edge_indx)\n",
        "# KarateClubGraph_feature = np.diag(np.ones(np.max(KarateClubGraph_edge_indx)+1))\n",
        "# KarateClubGraph_feature = torch.tensor(KarateClubGraph_feature, dtype = torch.float).to(device)\n",
        "# print(KarateClubGraph_feature.size())\n",
        "KarateClubGraph_edge_indx = [[row[i] for row in KarateClubGraph_edge_indx] for i in range(len(KarateClubGraph_edge_indx[0]))]\n",
        "print(KarateClubGraph_edge_indx)\n",
        "\n",
        "#for node in range(np.max(KarateClubGraph_edge_indx)+1):\n",
        "distance_features = torch.zeros((34,2), dtype = torch.float).to(device)\n",
        "print(distance_features.size())\n",
        "for node in range(34):\n",
        "    node2manger = nx.shortest_path(KarateClubGraph, source=node, target=0)\n",
        "    print('path {} , length {}'.format(node2manger, len(node2manger)))\n",
        "    node2coach = nx.shortest_path(KarateClubGraph, source=node, target=33)\n",
        "    print('path {} , length {}'.format(node2coach, len(node2coach)))\n",
        "    distance_features[node][0] = len(node2manger) - 1.0\n",
        "    distance_features[node][1] = len(node2coach) - 1.0\n",
        "print(distance_features)\n",
        "#KarateClubGraph_feature = torch.cat((KarateClubGraph_feature, distance_features),1)\n",
        "KarateClubGraph_feature = distance_features\n",
        "print(KarateClubGraph_feature.size())\n",
        "print(KarateClubGraph_feature)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 10], [0, 11], [0, 12], [0, 13], [0, 17], [0, 19], [0, 21], [0, 31], [1, 2], [1, 3], [1, 7], [1, 13], [1, 17], [1, 19], [1, 21], [1, 30], [2, 3], [2, 7], [2, 8], [2, 9], [2, 13], [2, 27], [2, 28], [2, 32], [3, 7], [3, 12], [3, 13], [4, 6], [4, 10], [5, 6], [5, 10], [5, 16], [6, 16], [8, 30], [8, 32], [8, 33], [9, 33], [13, 33], [14, 32], [14, 33], [15, 32], [15, 33], [18, 32], [18, 33], [19, 33], [20, 32], [20, 33], [22, 32], [22, 33], [23, 25], [23, 27], [23, 29], [23, 32], [23, 33], [24, 25], [24, 27], [24, 31], [25, 31], [26, 29], [26, 33], [27, 33], [28, 31], [28, 33], [29, 32], [29, 33], [30, 32], [30, 33], [31, 32], [31, 33], [32, 33]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 6, 8, 8, 8, 9, 13, 14, 14, 15, 15, 18, 18, 19, 20, 20, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 26, 26, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32], [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31, 2, 3, 7, 13, 17, 19, 21, 30, 3, 7, 8, 9, 13, 27, 28, 32, 7, 12, 13, 6, 10, 6, 10, 16, 16, 30, 32, 33, 33, 33, 32, 33, 32, 33, 32, 33, 33, 32, 33, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 31, 29, 33, 33, 31, 33, 32, 33, 32, 33, 32, 33, 33]]\n",
            "torch.Size([34, 2])\n",
            "path [0] , length 1\n",
            "path [0, 8, 33] , length 3\n",
            "path [1, 0] , length 2\n",
            "path [1, 13, 33] , length 3\n",
            "path [2, 0] , length 2\n",
            "path [2, 8, 33] , length 3\n",
            "path [3, 0] , length 2\n",
            "path [3, 13, 33] , length 3\n",
            "path [4, 0] , length 2\n",
            "path [4, 0, 8, 33] , length 4\n",
            "path [5, 0] , length 2\n",
            "path [5, 0, 8, 33] , length 4\n",
            "path [6, 0] , length 2\n",
            "path [6, 0, 8, 33] , length 4\n",
            "path [7, 0] , length 2\n",
            "path [7, 0, 8, 33] , length 4\n",
            "path [8, 0] , length 2\n",
            "path [8, 33] , length 2\n",
            "path [9, 2, 0] , length 3\n",
            "path [9, 33] , length 2\n",
            "path [10, 0] , length 2\n",
            "path [10, 0, 8, 33] , length 4\n",
            "path [11, 0] , length 2\n",
            "path [11, 0, 8, 33] , length 4\n",
            "path [12, 0] , length 2\n",
            "path [12, 0, 8, 33] , length 4\n",
            "path [13, 0] , length 2\n",
            "path [13, 33] , length 2\n",
            "path [14, 32, 2, 0] , length 4\n",
            "path [14, 33] , length 2\n",
            "path [15, 32, 2, 0] , length 4\n",
            "path [15, 33] , length 2\n",
            "path [16, 5, 0] , length 3\n",
            "path [16, 5, 0, 8, 33] , length 5\n",
            "path [17, 0] , length 2\n",
            "path [17, 0, 8, 33] , length 4\n",
            "path [18, 32, 2, 0] , length 4\n",
            "path [18, 33] , length 2\n",
            "path [19, 0] , length 2\n",
            "path [19, 33] , length 2\n",
            "path [20, 32, 2, 0] , length 4\n",
            "path [20, 33] , length 2\n",
            "path [21, 0] , length 2\n",
            "path [21, 0, 8, 33] , length 4\n",
            "path [22, 32, 2, 0] , length 4\n",
            "path [22, 33] , length 2\n",
            "path [23, 25, 31, 0] , length 4\n",
            "path [23, 33] , length 2\n",
            "path [24, 31, 0] , length 3\n",
            "path [24, 27, 33] , length 3\n",
            "path [25, 31, 0] , length 3\n",
            "path [25, 23, 33] , length 3\n",
            "path [26, 33, 8, 0] , length 4\n",
            "path [26, 33] , length 2\n",
            "path [27, 2, 0] , length 3\n",
            "path [27, 33] , length 2\n",
            "path [28, 2, 0] , length 3\n",
            "path [28, 33] , length 2\n",
            "path [29, 32, 2, 0] , length 4\n",
            "path [29, 33] , length 2\n",
            "path [30, 1, 0] , length 3\n",
            "path [30, 33] , length 2\n",
            "path [31, 0] , length 2\n",
            "path [31, 33] , length 2\n",
            "path [32, 2, 0] , length 3\n",
            "path [32, 33] , length 2\n",
            "path [33, 8, 0] , length 3\n",
            "path [33] , length 1\n",
            "tensor([[0., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 1.],\n",
            "        [2., 1.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 1.],\n",
            "        [3., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 4.],\n",
            "        [1., 3.],\n",
            "        [3., 1.],\n",
            "        [1., 1.],\n",
            "        [3., 1.],\n",
            "        [1., 3.],\n",
            "        [3., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 2.],\n",
            "        [2., 2.],\n",
            "        [3., 1.],\n",
            "        [2., 1.],\n",
            "        [2., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 1.],\n",
            "        [1., 1.],\n",
            "        [2., 1.],\n",
            "        [2., 0.]], device='cuda:0')\n",
            "torch.Size([34, 2])\n",
            "tensor([[0., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 1.],\n",
            "        [2., 1.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 3.],\n",
            "        [1., 1.],\n",
            "        [3., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 4.],\n",
            "        [1., 3.],\n",
            "        [3., 1.],\n",
            "        [1., 1.],\n",
            "        [3., 1.],\n",
            "        [1., 3.],\n",
            "        [3., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 2.],\n",
            "        [2., 2.],\n",
            "        [3., 1.],\n",
            "        [2., 1.],\n",
            "        [2., 1.],\n",
            "        [3., 1.],\n",
            "        [2., 1.],\n",
            "        [1., 1.],\n",
            "        [2., 1.],\n",
            "        [2., 0.]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOGgG2Vp7ivl",
        "colab_type": "code",
        "outputId": "5f6f1c5d-deef-4132-a200-ea1b151eb8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "edge_index = torch.tensor(KarateClubGraph_edge_indx, dtype = torch.long)\n",
        "node_features = torch.tensor(KarateClubGraph_feature, dtype = torch.float)\n",
        "KarateClubData = Data(x = node_features, edge_index = edge_index)\n",
        "print(KarateClubData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 78], x=[34, 2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snRQRgmP-o-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "class GCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "# Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "# Step 2: Linearly transform node feature matrix.\n",
        "        x = self.lin(x)\n",
        "# Step 3-5: Start propagating messages.\n",
        "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j has shape [E, out_channels]\n",
        "# Step 3: Normalize node features.\n",
        "        row, col = edge_index\n",
        "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "        return norm.view(-1, 1) * x_j\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "# Step 5: Return new node embeddings.\n",
        "        return aggr_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut7zvfG7-4iP",
        "colab_type": "code",
        "outputId": "daacc7e4-12fb-4fc5-cb64-7fb53456aec8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "def data_test():\n",
        "    Train_data = KarateClubData\n",
        "    print(Train_data.num_nodes)\n",
        "    Train_data.num_classes = 2\n",
        "    print('data classes num:{}'.format(Train_data.num_classes))\n",
        "    train_label = [0, 1]\n",
        "    pridct_lable = np.array(list(range(0,34)), dtype = np.float)\n",
        "    print(pridct_lable)\n",
        "    train_mask = np.zeros(pridct_lable.shape,dtype=np.bool)\n",
        "    train_mask[0] = 1\n",
        "    train_mask[25] = 1\n",
        "    print(pridct_lable[train_mask])\n",
        "    print('Train_data.num_node_features {}'.format(Train_data.num_node_features))\n",
        "    print('Train_data.edge_index {}'.format(Train_data.edge_index.shape))\n",
        "    pridct_lable[train_mask] = [0.02, 0.7]\n",
        "    print(pridct_lable[train_mask])\n",
        "    import torch.nn.functional as F\n",
        "    pridct = torch.tensor(pridct_lable[train_mask])\n",
        "    labels = torch.tensor(train_label)\n",
        "    input=torch.Tensor([[0.7715, 0.0205]])\n",
        "    loss = F.nll_loss(input,torch.tensor([0]))\n",
        "    print(loss)\n",
        "    # print(edge_index2.shape)\n",
        "    # conv1 = GCNConv(Train_data.num_node_features,128)\n",
        "    # print(Train_data.x)\n",
        "    # out = conv1(Train_data.x,Train_data.edge_index)\n",
        "    # print(out.shape)\n",
        "data_test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34\n",
            "data classes num:2\n",
            "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
            " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33.]\n",
            "[ 0. 25.]\n",
            "Train_data.num_node_features 2\n",
            "Train_data.edge_index torch.Size([2, 78])\n",
            "[0.02 0.7 ]\n",
            "tensor(-0.7715)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOcAbs51p__Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class GCN_Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN_Net, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channel, hidden_channels[0])\n",
        "        self.conv2 = GCNConv(hidden_channels[0], hidden_channels[1])\n",
        "        self.conv3 = GCNConv(hidden_channels[1], out_channel)\n",
        "    def forward(self,data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        #print(\"input x {}\".format(x))\n",
        "        #input x is [N, N]\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        #output x is [N, hidden_channels[0]] 64\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        # output [N,32]\n",
        "        x = self.conv3(x, edge_index)\n",
        "        # output [N, out_channel] out_channel = 2\n",
        "        return F.log_softmax(x, dim = 1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKhV1WBAq0TP",
        "colab_type": "text"
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA4WCqgfptTt",
        "colab_type": "code",
        "outputId": "197dd07b-f867-4141-d518-5f0739a62234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "#about model settings, and data\n",
        "Train_data = KarateClubData\n",
        "\n",
        "in_channel = Train_data.num_node_features\n",
        "Train_data.num_classes = 2\n",
        "out_channel = Train_data.num_classes\n",
        "hidden_channels = [34,5]\n",
        "data = KarateClubData\n",
        "#\n",
        "# train_mask = torch.zeros((in_channel,out_channel),dtype=torch.uint8)\n",
        "# train_mask[0] = 1\n",
        "# train_mask[33] = 1\n",
        "\n",
        "labeled_nodes = torch.tensor([0, 33]) \n",
        "#print(train_mask)\n",
        "data_y = torch.tensor([0,1])\n",
        "#about torch model\n",
        "data_y_labels = torch.tensor([0,0,0,0,0,0,0,0,0, 1, 0,0,0,0, 1,1, 0,0, 1,0, 1,0, 1,1,1,1,1,1,1,1,1,1,1,1]).to(device)\n",
        "print(len(data_y_labels))\n",
        "print('using ' + str(device))\n",
        "\n",
        "model = GCN_Net().to(device)\n",
        "data = data.to(device)\n",
        "data_y = data_y.to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "acc_best = 0.0\n",
        "best_epoch = 0\n",
        "best_pred = []\n",
        "\n",
        "data_edge_index_list =data.edge_index.tolist()\n",
        "data_edge_index_list = [[row[i] for row in data_edge_index_list] for i in range(len(data_edge_index_list[0]))]\n",
        "\n",
        "data_y_labels_list = data_y_labels.tolist()\n",
        "output_all = []\n",
        "for epoch in range(500):\n",
        "    model.train()\n",
        "    \n",
        "    out = model(data)\n",
        "    #print('out compute loss {}'.format(out[labeled_nodes].view(-1, out_channel)))\n",
        "    loss = F.nll_loss(out[labeled_nodes].view(-1, out_channel), data_y)\n",
        "    print(\"[{}] epoch  loss: {}\".format(epoch, loss.item()))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    #print(model(data))\n",
        "    output = model(data)\n",
        "    _, pred = output.max(dim = 1)\n",
        "    correct = float(pred.eq(data_y_labels).sum().item())\n",
        "    acc = correct / 34 * 100.0\n",
        "    if(acc > acc_best):\n",
        "        acc_best = acc\n",
        "        best_epoch = epoch\n",
        "        best_output = output.detach()\n",
        "    print(acc)\n",
        "    output_all.append((acc, output))\n",
        "    \n",
        "print('\\n\\nBest Accuracy:{}% in Epoch {} output{}'.format(acc_best, best_epoch , best_output))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34\n",
            "using cuda\n",
            "[0] epoch  loss: 0.4302835762500763\n",
            "0.6176470588235294\n",
            "[1] epoch  loss: 0.38894951343536377\n",
            "0.5294117647058824\n",
            "[2] epoch  loss: 0.36968082189559937\n",
            "0.5\n",
            "[3] epoch  loss: 0.3607173264026642\n",
            "0.5\n",
            "[4] epoch  loss: 0.3563750684261322\n",
            "0.5\n",
            "[5] epoch  loss: 0.35414111614227295\n",
            "0.5\n",
            "[6] epoch  loss: 0.35292279720306396\n",
            "0.5\n",
            "[7] epoch  loss: 0.3522244095802307\n",
            "0.5\n",
            "[8] epoch  loss: 0.3518068790435791\n",
            "0.5\n",
            "[9] epoch  loss: 0.351546049118042\n",
            "0.5\n",
            "[10] epoch  loss: 0.3513783812522888\n",
            "0.5\n",
            "[11] epoch  loss: 0.35126614570617676\n",
            "0.5\n",
            "[12] epoch  loss: 0.3511889576911926\n",
            "0.5\n",
            "[13] epoch  loss: 0.35113444924354553\n",
            "0.5\n",
            "[14] epoch  loss: 0.35109513998031616\n",
            "0.5\n",
            "[15] epoch  loss: 0.3510660231113434\n",
            "0.5\n",
            "[16] epoch  loss: 0.3510439991950989\n",
            "0.5\n",
            "[17] epoch  loss: 0.3510272800922394\n",
            "0.5\n",
            "[18] epoch  loss: 0.35101401805877686\n",
            "0.5\n",
            "[19] epoch  loss: 0.3510035276412964\n",
            "0.5\n",
            "[20] epoch  loss: 0.35099491477012634\n",
            "0.5\n",
            "[21] epoch  loss: 0.3509877324104309\n",
            "0.5\n",
            "[22] epoch  loss: 0.35098153352737427\n",
            "0.5\n",
            "[23] epoch  loss: 0.3509764075279236\n",
            "0.5\n",
            "[24] epoch  loss: 0.35097163915634155\n",
            "0.5\n",
            "[25] epoch  loss: 0.3509674370288849\n",
            "0.5\n",
            "[26] epoch  loss: 0.35096344351768494\n",
            "0.5\n",
            "[27] epoch  loss: 0.3509599268436432\n",
            "0.5\n",
            "[28] epoch  loss: 0.35095658898353577\n",
            "0.5\n",
            "[29] epoch  loss: 0.35095328092575073\n",
            "0.5\n",
            "[30] epoch  loss: 0.3509499728679657\n",
            "0.5\n",
            "[31] epoch  loss: 0.3509467840194702\n",
            "0.5\n",
            "[32] epoch  loss: 0.35094359517097473\n",
            "0.5\n",
            "[33] epoch  loss: 0.3509403169155121\n",
            "0.5\n",
            "[34] epoch  loss: 0.3509370982646942\n",
            "0.5\n",
            "[35] epoch  loss: 0.3509337306022644\n",
            "0.5\n",
            "[36] epoch  loss: 0.35093048214912415\n",
            "0.5\n",
            "[37] epoch  loss: 0.35092708468437195\n",
            "0.5\n",
            "[38] epoch  loss: 0.3509238660335541\n",
            "0.5\n",
            "[39] epoch  loss: 0.3509202301502228\n",
            "0.5\n",
            "[40] epoch  loss: 0.35091695189476013\n",
            "0.5\n",
            "[41] epoch  loss: 0.35091331601142883\n",
            "0.5\n",
            "[42] epoch  loss: 0.3509098291397095\n",
            "0.5\n",
            "[43] epoch  loss: 0.3509064316749573\n",
            "0.5\n",
            "[44] epoch  loss: 0.3509027063846588\n",
            "0.5\n",
            "[45] epoch  loss: 0.3508991003036499\n",
            "0.5\n",
            "[46] epoch  loss: 0.3508951961994171\n",
            "0.5\n",
            "[47] epoch  loss: 0.3508914113044739\n",
            "0.5\n",
            "[48] epoch  loss: 0.3508875370025635\n",
            "0.5\n",
            "[49] epoch  loss: 0.350883811712265\n",
            "0.5\n",
            "[50] epoch  loss: 0.35087984800338745\n",
            "0.5\n",
            "[51] epoch  loss: 0.35087576508522034\n",
            "0.5\n",
            "[52] epoch  loss: 0.35087186098098755\n",
            "0.5\n",
            "[53] epoch  loss: 0.35086771845817566\n",
            "0.5\n",
            "[54] epoch  loss: 0.3508636951446533\n",
            "0.5\n",
            "[55] epoch  loss: 0.3508594036102295\n",
            "0.5\n",
            "[56] epoch  loss: 0.3508553206920624\n",
            "0.5\n",
            "[57] epoch  loss: 0.3508511781692505\n",
            "0.5\n",
            "[58] epoch  loss: 0.3508467674255371\n",
            "0.5\n",
            "[59] epoch  loss: 0.35084250569343567\n",
            "0.5\n",
            "[60] epoch  loss: 0.35083821415901184\n",
            "0.5\n",
            "[61] epoch  loss: 0.35083362460136414\n",
            "0.5\n",
            "[62] epoch  loss: 0.35082921385765076\n",
            "0.5\n",
            "[63] epoch  loss: 0.3508248031139374\n",
            "0.5\n",
            "[64] epoch  loss: 0.35082027316093445\n",
            "0.5\n",
            "[65] epoch  loss: 0.35081571340560913\n",
            "0.5\n",
            "[66] epoch  loss: 0.3508111238479614\n",
            "0.5\n",
            "[67] epoch  loss: 0.35080647468566895\n",
            "0.5\n",
            "[68] epoch  loss: 0.3508017659187317\n",
            "0.5\n",
            "[69] epoch  loss: 0.35079699754714966\n",
            "0.5\n",
            "[70] epoch  loss: 0.3507922291755676\n",
            "0.5\n",
            "[71] epoch  loss: 0.3507874310016632\n",
            "0.5\n",
            "[72] epoch  loss: 0.35078251361846924\n",
            "0.5\n",
            "[73] epoch  loss: 0.3507777750492096\n",
            "0.5\n",
            "[74] epoch  loss: 0.3507728576660156\n",
            "0.5\n",
            "[75] epoch  loss: 0.3507678508758545\n",
            "0.5\n",
            "[76] epoch  loss: 0.3507627844810486\n",
            "0.5\n",
            "[77] epoch  loss: 0.3507579267024994\n",
            "0.5\n",
            "[78] epoch  loss: 0.3507527709007263\n",
            "0.5\n",
            "[79] epoch  loss: 0.35074764490127563\n",
            "0.5\n",
            "[80] epoch  loss: 0.3507424592971802\n",
            "0.5\n",
            "[81] epoch  loss: 0.35073742270469666\n",
            "0.5\n",
            "[82] epoch  loss: 0.3507322072982788\n",
            "0.5\n",
            "[83] epoch  loss: 0.3507269322872162\n",
            "0.5\n",
            "[84] epoch  loss: 0.3507215976715088\n",
            "0.5\n",
            "[85] epoch  loss: 0.3507162630558014\n",
            "0.5\n",
            "[86] epoch  loss: 0.3507111072540283\n",
            "0.5\n",
            "[87] epoch  loss: 0.35070568323135376\n",
            "0.5\n",
            "[88] epoch  loss: 0.3507002294063568\n",
            "0.5\n",
            "[89] epoch  loss: 0.3506946861743927\n",
            "0.5\n",
            "[90] epoch  loss: 0.3506893813610077\n",
            "0.5\n",
            "[91] epoch  loss: 0.3506838083267212\n",
            "0.5\n",
            "[92] epoch  loss: 0.3506782054901123\n",
            "0.5\n",
            "[93] epoch  loss: 0.35067254304885864\n",
            "0.5\n",
            "[94] epoch  loss: 0.3506670594215393\n",
            "0.5\n",
            "[95] epoch  loss: 0.3506613075733185\n",
            "0.5\n",
            "[96] epoch  loss: 0.35065579414367676\n",
            "0.5\n",
            "[97] epoch  loss: 0.35064998269081116\n",
            "0.5\n",
            "[98] epoch  loss: 0.35064417123794556\n",
            "0.5\n",
            "[99] epoch  loss: 0.3506383001804352\n",
            "0.5\n",
            "[100] epoch  loss: 0.3506326675415039\n",
            "0.5\n",
            "[101] epoch  loss: 0.35062673687934875\n",
            "0.5\n",
            "[102] epoch  loss: 0.3506208062171936\n",
            "0.5\n",
            "[103] epoch  loss: 0.3506150245666504\n",
            "0.5\n",
            "[104] epoch  loss: 0.3506090044975281\n",
            "0.5\n",
            "[105] epoch  loss: 0.3506029546260834\n",
            "0.5\n",
            "[106] epoch  loss: 0.3505970537662506\n",
            "0.5\n",
            "[107] epoch  loss: 0.35059091448783875\n",
            "0.5\n",
            "[108] epoch  loss: 0.3505847752094269\n",
            "0.5\n",
            "[109] epoch  loss: 0.35057878494262695\n",
            "0.5\n",
            "[110] epoch  loss: 0.3505726158618927\n",
            "0.5\n",
            "[111] epoch  loss: 0.3505662977695465\n",
            "0.5\n",
            "[112] epoch  loss: 0.3505600392818451\n",
            "0.5\n",
            "[113] epoch  loss: 0.3505539894104004\n",
            "0.5\n",
            "[114] epoch  loss: 0.35054758191108704\n",
            "0.5\n",
            "[115] epoch  loss: 0.35054123401641846\n",
            "0.5\n",
            "[116] epoch  loss: 0.35053500533103943\n",
            "0.5\n",
            "[117] epoch  loss: 0.3505285680294037\n",
            "0.5\n",
            "[118] epoch  loss: 0.35052210092544556\n",
            "0.5\n",
            "[119] epoch  loss: 0.35051578283309937\n",
            "0.5\n",
            "[120] epoch  loss: 0.35050925612449646\n",
            "0.5\n",
            "[121] epoch  loss: 0.35050293803215027\n",
            "0.5\n",
            "[122] epoch  loss: 0.35049623250961304\n",
            "0.5\n",
            "[123] epoch  loss: 0.3504895865917206\n",
            "0.5\n",
            "[124] epoch  loss: 0.35048314929008484\n",
            "0.5\n",
            "[125] epoch  loss: 0.35047647356987\n",
            "0.5\n",
            "[126] epoch  loss: 0.350469708442688\n",
            "0.5\n",
            "[127] epoch  loss: 0.35046321153640747\n",
            "0.5\n",
            "[128] epoch  loss: 0.3504563570022583\n",
            "0.5\n",
            "[129] epoch  loss: 0.35044950246810913\n",
            "0.5\n",
            "[130] epoch  loss: 0.35044291615486145\n",
            "0.5\n",
            "[131] epoch  loss: 0.3504360020160675\n",
            "0.5\n",
            "[132] epoch  loss: 0.35042932629585266\n",
            "0.5\n",
            "[133] epoch  loss: 0.35042235255241394\n",
            "0.5\n",
            "[134] epoch  loss: 0.3504153788089752\n",
            "0.5\n",
            "[135] epoch  loss: 0.3504086136817932\n",
            "0.5\n",
            "[136] epoch  loss: 0.35040155053138733\n",
            "0.5\n",
            "[137] epoch  loss: 0.35039448738098145\n",
            "0.5\n",
            "[138] epoch  loss: 0.3503873646259308\n",
            "0.5\n",
            "[139] epoch  loss: 0.3503805100917816\n",
            "0.5\n",
            "[140] epoch  loss: 0.35037335753440857\n",
            "0.5\n",
            "[141] epoch  loss: 0.35036614537239075\n",
            "0.5\n",
            "[142] epoch  loss: 0.350359171628952\n",
            "0.5\n",
            "[143] epoch  loss: 0.3503519594669342\n",
            "0.5\n",
            "[144] epoch  loss: 0.3503446877002716\n",
            "0.5\n",
            "[145] epoch  loss: 0.3503373861312866\n",
            "0.5\n",
            "[146] epoch  loss: 0.35033026337623596\n",
            "0.5\n",
            "[147] epoch  loss: 0.3503229022026062\n",
            "0.5\n",
            "[148] epoch  loss: 0.35031557083129883\n",
            "0.5\n",
            "[149] epoch  loss: 0.3503081202507019\n",
            "0.5\n",
            "[150] epoch  loss: 0.350300669670105\n",
            "0.5\n",
            "[151] epoch  loss: 0.35029342770576477\n",
            "0.5\n",
            "[152] epoch  loss: 0.35028594732284546\n",
            "0.5\n",
            "[153] epoch  loss: 0.35027846693992615\n",
            "0.5\n",
            "[154] epoch  loss: 0.3502708971500397\n",
            "0.5\n",
            "[155] epoch  loss: 0.3502632677555084\n",
            "0.5\n",
            "[156] epoch  loss: 0.35025566816329956\n",
            "0.5\n",
            "[157] epoch  loss: 0.3502480685710907\n",
            "0.5\n",
            "[158] epoch  loss: 0.3502406179904938\n",
            "0.5\n",
            "[159] epoch  loss: 0.35023295879364014\n",
            "0.5\n",
            "[160] epoch  loss: 0.35022521018981934\n",
            "0.5\n",
            "[161] epoch  loss: 0.35021743178367615\n",
            "0.5294117647058824\n",
            "[162] epoch  loss: 0.35020968317985535\n",
            "0.5294117647058824\n",
            "[163] epoch  loss: 0.35020187497138977\n",
            "0.5294117647058824\n",
            "[164] epoch  loss: 0.3501940667629242\n",
            "0.5294117647058824\n",
            "[165] epoch  loss: 0.35018619894981384\n",
            "0.5294117647058824\n",
            "[166] epoch  loss: 0.3501782715320587\n",
            "0.5294117647058824\n",
            "[167] epoch  loss: 0.350170373916626\n",
            "0.5294117647058824\n",
            "[168] epoch  loss: 0.35016244649887085\n",
            "0.5294117647058824\n",
            "[169] epoch  loss: 0.35015445947647095\n",
            "0.5294117647058824\n",
            "[170] epoch  loss: 0.35014647245407104\n",
            "0.5588235294117647\n",
            "[171] epoch  loss: 0.35013842582702637\n",
            "0.5588235294117647\n",
            "[172] epoch  loss: 0.3501303791999817\n",
            "0.5588235294117647\n",
            "[173] epoch  loss: 0.350122332572937\n",
            "0.5588235294117647\n",
            "[174] epoch  loss: 0.3501141667366028\n",
            "0.5588235294117647\n",
            "[175] epoch  loss: 0.35010606050491333\n",
            "0.5588235294117647\n",
            "[176] epoch  loss: 0.3500978648662567\n",
            "0.5588235294117647\n",
            "[177] epoch  loss: 0.3500896990299225\n",
            "0.5588235294117647\n",
            "[178] epoch  loss: 0.3500814437866211\n",
            "0.5588235294117647\n",
            "[179] epoch  loss: 0.3500731587409973\n",
            "0.5588235294117647\n",
            "[180] epoch  loss: 0.3500649034976959\n",
            "0.5588235294117647\n",
            "[181] epoch  loss: 0.35005658864974976\n",
            "0.5588235294117647\n",
            "[182] epoch  loss: 0.3500482141971588\n",
            "0.5588235294117647\n",
            "[183] epoch  loss: 0.35003983974456787\n",
            "0.5588235294117647\n",
            "[184] epoch  loss: 0.35003143548965454\n",
            "0.5588235294117647\n",
            "[185] epoch  loss: 0.3500230312347412\n",
            "0.5588235294117647\n",
            "[186] epoch  loss: 0.3500145673751831\n",
            "0.5588235294117647\n",
            "[187] epoch  loss: 0.3500060439109802\n",
            "0.5588235294117647\n",
            "[188] epoch  loss: 0.3499975800514221\n",
            "0.5588235294117647\n",
            "[189] epoch  loss: 0.34998902678489685\n",
            "0.5588235294117647\n",
            "[190] epoch  loss: 0.3499804437160492\n",
            "0.5588235294117647\n",
            "[191] epoch  loss: 0.34997180104255676\n",
            "0.5588235294117647\n",
            "[192] epoch  loss: 0.3499631881713867\n",
            "0.5588235294117647\n",
            "[193] epoch  loss: 0.3499545753002167\n",
            "0.5588235294117647\n",
            "[194] epoch  loss: 0.34994587302207947\n",
            "0.5588235294117647\n",
            "[195] epoch  loss: 0.34993690252304077\n",
            "0.5588235294117647\n",
            "[196] epoch  loss: 0.3499281406402588\n",
            "0.5588235294117647\n",
            "[197] epoch  loss: 0.3499193787574768\n",
            "0.5588235294117647\n",
            "[198] epoch  loss: 0.3499106168746948\n",
            "0.5588235294117647\n",
            "[199] epoch  loss: 0.3499017655849457\n",
            "0.5588235294117647\n",
            "[200] epoch  loss: 0.34989291429519653\n",
            "0.5588235294117647\n",
            "[201] epoch  loss: 0.349884033203125\n",
            "0.5588235294117647\n",
            "[202] epoch  loss: 0.3498750627040863\n",
            "0.5588235294117647\n",
            "[203] epoch  loss: 0.3498660922050476\n",
            "0.5588235294117647\n",
            "[204] epoch  loss: 0.3498571515083313\n",
            "0.5588235294117647\n",
            "[205] epoch  loss: 0.3498481214046478\n",
            "0.5588235294117647\n",
            "[206] epoch  loss: 0.34983912110328674\n",
            "0.5588235294117647\n",
            "[207] epoch  loss: 0.3498300313949585\n",
            "0.5588235294117647\n",
            "[208] epoch  loss: 0.34982097148895264\n",
            "0.5588235294117647\n",
            "[209] epoch  loss: 0.349811851978302\n",
            "0.5588235294117647\n",
            "[210] epoch  loss: 0.3498024344444275\n",
            "0.5588235294117647\n",
            "[211] epoch  loss: 0.34979328513145447\n",
            "0.5588235294117647\n",
            "[212] epoch  loss: 0.3497840464115143\n",
            "0.5588235294117647\n",
            "[213] epoch  loss: 0.3497748076915741\n",
            "0.5882352941176471\n",
            "[214] epoch  loss: 0.3497655391693115\n",
            "0.6470588235294118\n",
            "[215] epoch  loss: 0.3497562110424042\n",
            "0.6470588235294118\n",
            "[216] epoch  loss: 0.3497468829154968\n",
            "0.6470588235294118\n",
            "[217] epoch  loss: 0.3497375547885895\n",
            "0.6470588235294118\n",
            "[218] epoch  loss: 0.3497281074523926\n",
            "0.6470588235294118\n",
            "[219] epoch  loss: 0.34971871972084045\n",
            "0.6470588235294118\n",
            "[220] epoch  loss: 0.34970927238464355\n",
            "0.6470588235294118\n",
            "[221] epoch  loss: 0.34969979524612427\n",
            "0.6470588235294118\n",
            "[222] epoch  loss: 0.349690318107605\n",
            "0.6470588235294118\n",
            "[223] epoch  loss: 0.3496808111667633\n",
            "0.6470588235294118\n",
            "[224] epoch  loss: 0.34967121481895447\n",
            "0.6470588235294118\n",
            "[225] epoch  loss: 0.34966161847114563\n",
            "0.6470588235294118\n",
            "[226] epoch  loss: 0.3496520221233368\n",
            "0.6470588235294118\n",
            "[227] epoch  loss: 0.34964239597320557\n",
            "0.6470588235294118\n",
            "[228] epoch  loss: 0.3496324121952057\n",
            "0.6470588235294118\n",
            "[229] epoch  loss: 0.3496226966381073\n",
            "0.6470588235294118\n",
            "[230] epoch  loss: 0.3496130108833313\n",
            "0.6470588235294118\n",
            "[231] epoch  loss: 0.34960320591926575\n",
            "0.6470588235294118\n",
            "[232] epoch  loss: 0.3495934307575226\n",
            "0.6470588235294118\n",
            "[233] epoch  loss: 0.34958356618881226\n",
            "0.6470588235294118\n",
            "[234] epoch  loss: 0.3495737314224243\n",
            "0.6470588235294118\n",
            "[235] epoch  loss: 0.349563866853714\n",
            "0.6470588235294118\n",
            "[236] epoch  loss: 0.3495539426803589\n",
            "0.6470588235294118\n",
            "[237] epoch  loss: 0.3495440185070038\n",
            "0.6470588235294118\n",
            "[238] epoch  loss: 0.3495340347290039\n",
            "0.6470588235294118\n",
            "[239] epoch  loss: 0.34952402114868164\n",
            "0.6470588235294118\n",
            "[240] epoch  loss: 0.349513977766037\n",
            "0.6470588235294118\n",
            "[241] epoch  loss: 0.34950390458106995\n",
            "0.6470588235294118\n",
            "[242] epoch  loss: 0.3494938611984253\n",
            "0.6470588235294118\n",
            "[243] epoch  loss: 0.3494837284088135\n",
            "0.6470588235294118\n",
            "[244] epoch  loss: 0.34947359561920166\n",
            "0.6470588235294118\n",
            "[245] epoch  loss: 0.34946343302726746\n",
            "0.6470588235294118\n",
            "[246] epoch  loss: 0.34945327043533325\n",
            "0.6470588235294118\n",
            "[247] epoch  loss: 0.34944289922714233\n",
            "0.6470588235294118\n",
            "[248] epoch  loss: 0.34943270683288574\n",
            "0.6470588235294118\n",
            "[249] epoch  loss: 0.34942230582237244\n",
            "0.6764705882352942\n",
            "[250] epoch  loss: 0.34941214323043823\n",
            "0.6764705882352942\n",
            "[251] epoch  loss: 0.34940171241760254\n",
            "0.6764705882352942\n",
            "[252] epoch  loss: 0.34939125180244446\n",
            "0.6764705882352942\n",
            "[253] epoch  loss: 0.3493810296058655\n",
            "0.6764705882352942\n",
            "[254] epoch  loss: 0.3493705093860626\n",
            "0.6764705882352942\n",
            "[255] epoch  loss: 0.34936004877090454\n",
            "0.6764705882352942\n",
            "[256] epoch  loss: 0.3493495285511017\n",
            "0.6764705882352942\n",
            "[257] epoch  loss: 0.34933900833129883\n",
            "0.6764705882352942\n",
            "[258] epoch  loss: 0.3493284583091736\n",
            "0.6764705882352942\n",
            "[259] epoch  loss: 0.34931790828704834\n",
            "0.6764705882352942\n",
            "[260] epoch  loss: 0.34930726885795593\n",
            "0.6764705882352942\n",
            "[261] epoch  loss: 0.3492967188358307\n",
            "0.6764705882352942\n",
            "[262] epoch  loss: 0.3492860496044159\n",
            "0.6764705882352942\n",
            "[263] epoch  loss: 0.3492753505706787\n",
            "0.6764705882352942\n",
            "[264] epoch  loss: 0.3492644429206848\n",
            "0.6764705882352942\n",
            "[265] epoch  loss: 0.34925374388694763\n",
            "0.6764705882352942\n",
            "[266] epoch  loss: 0.34924307465553284\n",
            "0.6764705882352942\n",
            "[267] epoch  loss: 0.34923213720321655\n",
            "0.6764705882352942\n",
            "[268] epoch  loss: 0.349221408367157\n",
            "0.6764705882352942\n",
            "[269] epoch  loss: 0.3492104709148407\n",
            "0.6764705882352942\n",
            "[270] epoch  loss: 0.3491995334625244\n",
            "0.6764705882352942\n",
            "[271] epoch  loss: 0.34918877482414246\n",
            "0.6764705882352942\n",
            "[272] epoch  loss: 0.3491778075695038\n",
            "0.6764705882352942\n",
            "[273] epoch  loss: 0.3491668105125427\n",
            "0.6764705882352942\n",
            "[274] epoch  loss: 0.34915581345558167\n",
            "0.7058823529411765\n",
            "[275] epoch  loss: 0.3491447865962982\n",
            "0.7058823529411765\n",
            "[276] epoch  loss: 0.3491337299346924\n",
            "0.7058823529411765\n",
            "[277] epoch  loss: 0.34912243485450745\n",
            "0.7058823529411765\n",
            "[278] epoch  loss: 0.3491113483905792\n",
            "0.7058823529411765\n",
            "[279] epoch  loss: 0.34910035133361816\n",
            "0.7058823529411765\n",
            "[280] epoch  loss: 0.3490890860557556\n",
            "0.7058823529411765\n",
            "[281] epoch  loss: 0.3490777611732483\n",
            "0.7058823529411765\n",
            "[282] epoch  loss: 0.34906673431396484\n",
            "0.7058823529411765\n",
            "[283] epoch  loss: 0.3490554392337799\n",
            "0.7058823529411765\n",
            "[284] epoch  loss: 0.3490440845489502\n",
            "0.7058823529411765\n",
            "[285] epoch  loss: 0.34903275966644287\n",
            "0.7058823529411765\n",
            "[286] epoch  loss: 0.34902140498161316\n",
            "0.7058823529411765\n",
            "[287] epoch  loss: 0.3490098714828491\n",
            "0.7058823529411765\n",
            "[288] epoch  loss: 0.3489985167980194\n",
            "0.7058823529411765\n",
            "[289] epoch  loss: 0.3489871919155121\n",
            "0.7058823529411765\n",
            "[290] epoch  loss: 0.3489755392074585\n",
            "0.7058823529411765\n",
            "[291] epoch  loss: 0.34896421432495117\n",
            "0.7058823529411765\n",
            "[292] epoch  loss: 0.34895265102386475\n",
            "0.7058823529411765\n",
            "[293] epoch  loss: 0.34894102811813354\n",
            "0.7058823529411765\n",
            "[294] epoch  loss: 0.34892943501472473\n",
            "0.7058823529411765\n",
            "[295] epoch  loss: 0.3489178419113159\n",
            "0.7058823529411765\n",
            "[296] epoch  loss: 0.34890618920326233\n",
            "0.7058823529411765\n",
            "[297] epoch  loss: 0.3488945960998535\n",
            "0.7058823529411765\n",
            "[298] epoch  loss: 0.3488829731941223\n",
            "0.7352941176470589\n",
            "[299] epoch  loss: 0.348871111869812\n",
            "0.7352941176470589\n",
            "[300] epoch  loss: 0.3488594591617584\n",
            "0.7352941176470589\n",
            "[301] epoch  loss: 0.3488475978374481\n",
            "0.7647058823529411\n",
            "[302] epoch  loss: 0.3488357663154602\n",
            "0.7647058823529411\n",
            "[303] epoch  loss: 0.3488238751888275\n",
            "0.7647058823529411\n",
            "[304] epoch  loss: 0.3488120436668396\n",
            "0.7647058823529411\n",
            "[305] epoch  loss: 0.3488001525402069\n",
            "0.7647058823529411\n",
            "[306] epoch  loss: 0.3487882912158966\n",
            "0.7647058823529411\n",
            "[307] epoch  loss: 0.3487764000892639\n",
            "0.7941176470588235\n",
            "[308] epoch  loss: 0.3487642705440521\n",
            "0.7941176470588235\n",
            "[309] epoch  loss: 0.34875214099884033\n",
            "0.7941176470588235\n",
            "[310] epoch  loss: 0.3487403094768524\n",
            "0.7941176470588235\n",
            "[311] epoch  loss: 0.3487282395362854\n",
            "0.7941176470588235\n",
            "[312] epoch  loss: 0.348716139793396\n",
            "0.7941176470588235\n",
            "[313] epoch  loss: 0.3487038016319275\n",
            "0.7941176470588235\n",
            "[314] epoch  loss: 0.3486917316913605\n",
            "0.7941176470588235\n",
            "[315] epoch  loss: 0.34867963194847107\n",
            "0.7941176470588235\n",
            "[316] epoch  loss: 0.3486672639846802\n",
            "0.7941176470588235\n",
            "[317] epoch  loss: 0.34865519404411316\n",
            "0.7941176470588235\n",
            "[318] epoch  loss: 0.34864291548728943\n",
            "0.7941176470588235\n",
            "[319] epoch  loss: 0.3486306071281433\n",
            "0.8235294117647058\n",
            "[320] epoch  loss: 0.3486182987689972\n",
            "0.8235294117647058\n",
            "[321] epoch  loss: 0.34860605001449585\n",
            "0.8235294117647058\n",
            "[322] epoch  loss: 0.34859347343444824\n",
            "0.8235294117647058\n",
            "[323] epoch  loss: 0.34858113527297974\n",
            "0.8235294117647058\n",
            "[324] epoch  loss: 0.3485686182975769\n",
            "0.8235294117647058\n",
            "[325] epoch  loss: 0.3485563099384308\n",
            "0.8235294117647058\n",
            "[326] epoch  loss: 0.34854376316070557\n",
            "0.8235294117647058\n",
            "[327] epoch  loss: 0.34853124618530273\n",
            "0.8529411764705882\n",
            "[328] epoch  loss: 0.3485186994075775\n",
            "0.8529411764705882\n",
            "[329] epoch  loss: 0.3485061824321747\n",
            "0.8529411764705882\n",
            "[330] epoch  loss: 0.3484936058521271\n",
            "0.8529411764705882\n",
            "[331] epoch  loss: 0.3484809100627899\n",
            "0.8529411764705882\n",
            "[332] epoch  loss: 0.3484683632850647\n",
            "0.8529411764705882\n",
            "[333] epoch  loss: 0.34845563769340515\n",
            "0.8529411764705882\n",
            "[334] epoch  loss: 0.3484429121017456\n",
            "0.8529411764705882\n",
            "[335] epoch  loss: 0.34843021631240845\n",
            "0.8529411764705882\n",
            "[336] epoch  loss: 0.3484172821044922\n",
            "0.8529411764705882\n",
            "[337] epoch  loss: 0.34840455651283264\n",
            "0.8529411764705882\n",
            "[338] epoch  loss: 0.3483918309211731\n",
            "0.8529411764705882\n",
            "[339] epoch  loss: 0.34837889671325684\n",
            "0.8529411764705882\n",
            "[340] epoch  loss: 0.34836599230766296\n",
            "0.8529411764705882\n",
            "[341] epoch  loss: 0.3483530282974243\n",
            "0.8529411764705882\n",
            "[342] epoch  loss: 0.34834012389183044\n",
            "0.8529411764705882\n",
            "[343] epoch  loss: 0.3483272194862366\n",
            "0.8529411764705882\n",
            "[344] epoch  loss: 0.3483143150806427\n",
            "0.8529411764705882\n",
            "[345] epoch  loss: 0.34830114245414734\n",
            "0.8529411764705882\n",
            "[346] epoch  loss: 0.3482882082462311\n",
            "0.8529411764705882\n",
            "[347] epoch  loss: 0.3482751250267029\n",
            "0.8529411764705882\n",
            "[348] epoch  loss: 0.3482619822025299\n",
            "0.8529411764705882\n",
            "[349] epoch  loss: 0.3482488691806793\n",
            "0.8529411764705882\n",
            "[350] epoch  loss: 0.3482357859611511\n",
            "0.8529411764705882\n",
            "[351] epoch  loss: 0.3482224643230438\n",
            "0.8529411764705882\n",
            "[352] epoch  loss: 0.34820932149887085\n",
            "0.8529411764705882\n",
            "[353] epoch  loss: 0.3481959402561188\n",
            "0.9117647058823529\n",
            "[354] epoch  loss: 0.34818288683891296\n",
            "0.9117647058823529\n",
            "[355] epoch  loss: 0.3481695353984833\n",
            "0.9117647058823529\n",
            "[356] epoch  loss: 0.34815600514411926\n",
            "0.9117647058823529\n",
            "[357] epoch  loss: 0.34814271330833435\n",
            "0.9117647058823529\n",
            "[358] epoch  loss: 0.34812942147254944\n",
            "0.9117647058823529\n",
            "[359] epoch  loss: 0.3481161296367645\n",
            "0.9117647058823529\n",
            "[360] epoch  loss: 0.3481025993824005\n",
            "0.9117647058823529\n",
            "[361] epoch  loss: 0.3480890989303589\n",
            "0.9117647058823529\n",
            "[362] epoch  loss: 0.34807565808296204\n",
            "0.9117647058823529\n",
            "[363] epoch  loss: 0.3480621874332428\n",
            "0.9117647058823529\n",
            "[364] epoch  loss: 0.34804847836494446\n",
            "0.9117647058823529\n",
            "[365] epoch  loss: 0.3480350077152252\n",
            "0.9117647058823529\n",
            "[366] epoch  loss: 0.3480212986469269\n",
            "0.9117647058823529\n",
            "[367] epoch  loss: 0.3480076193809509\n",
            "0.9117647058823529\n",
            "[368] epoch  loss: 0.347993940114975\n",
            "0.9117647058823529\n",
            "[369] epoch  loss: 0.3479803204536438\n",
            "0.9117647058823529\n",
            "[370] epoch  loss: 0.34796667098999023\n",
            "0.9117647058823529\n",
            "[371] epoch  loss: 0.34795305132865906\n",
            "0.9117647058823529\n",
            "[372] epoch  loss: 0.3479391038417816\n",
            "0.9117647058823529\n",
            "[373] epoch  loss: 0.34792521595954895\n",
            "0.9117647058823529\n",
            "[374] epoch  loss: 0.3479115962982178\n",
            "0.9411764705882353\n",
            "[375] epoch  loss: 0.34789779782295227\n",
            "0.9411764705882353\n",
            "[376] epoch  loss: 0.3478837311267853\n",
            "0.9411764705882353\n",
            "[377] epoch  loss: 0.34786978363990784\n",
            "0.9411764705882353\n",
            "[378] epoch  loss: 0.3478560745716095\n",
            "0.9411764705882353\n",
            "[379] epoch  loss: 0.34784188866615295\n",
            "0.9411764705882353\n",
            "[380] epoch  loss: 0.3478280007839203\n",
            "0.9411764705882353\n",
            "[381] epoch  loss: 0.34781381487846375\n",
            "0.9411764705882353\n",
            "[382] epoch  loss: 0.3477999269962311\n",
            "0.9117647058823529\n",
            "[383] epoch  loss: 0.3477857708930969\n",
            "0.9117647058823529\n",
            "[384] epoch  loss: 0.34777161478996277\n",
            "0.9117647058823529\n",
            "[385] epoch  loss: 0.3477574586868286\n",
            "0.9117647058823529\n",
            "[386] epoch  loss: 0.3477432429790497\n",
            "0.9411764705882353\n",
            "[387] epoch  loss: 0.3477290868759155\n",
            "0.9411764705882353\n",
            "[388] epoch  loss: 0.34771499037742615\n",
            "0.9411764705882353\n",
            "[389] epoch  loss: 0.34770068526268005\n",
            "0.9411764705882353\n",
            "[390] epoch  loss: 0.34768638014793396\n",
            "0.9411764705882353\n",
            "[391] epoch  loss: 0.34767210483551025\n",
            "0.9411764705882353\n",
            "[392] epoch  loss: 0.34765762090682983\n",
            "0.9411764705882353\n",
            "[393] epoch  loss: 0.3476433753967285\n",
            "0.9411764705882353\n",
            "[394] epoch  loss: 0.3476288914680481\n",
            "0.9411764705882353\n",
            "[395] epoch  loss: 0.3476146459579468\n",
            "0.9411764705882353\n",
            "[396] epoch  loss: 0.3476001024246216\n",
            "0.9411764705882353\n",
            "[397] epoch  loss: 0.347585529088974\n",
            "0.9411764705882353\n",
            "[398] epoch  loss: 0.34757107496261597\n",
            "0.9411764705882353\n",
            "[399] epoch  loss: 0.3475566506385803\n",
            "0.9411764705882353\n",
            "[400] epoch  loss: 0.3475419580936432\n",
            "0.9411764705882353\n",
            "[401] epoch  loss: 0.3475276231765747\n",
            "0.9411764705882353\n",
            "[402] epoch  loss: 0.3475130796432495\n",
            "0.9411764705882353\n",
            "[403] epoch  loss: 0.3474982976913452\n",
            "0.9411764705882353\n",
            "[404] epoch  loss: 0.3474837839603424\n",
            "0.9411764705882353\n",
            "[405] epoch  loss: 0.3474690914154053\n",
            "0.9411764705882353\n",
            "[406] epoch  loss: 0.34745433926582336\n",
            "0.9411764705882353\n",
            "[407] epoch  loss: 0.3474396765232086\n",
            "0.9411764705882353\n",
            "[408] epoch  loss: 0.3474249243736267\n",
            "0.9411764705882353\n",
            "[409] epoch  loss: 0.3474101424217224\n",
            "0.9411764705882353\n",
            "[410] epoch  loss: 0.3473954200744629\n",
            "0.9411764705882353\n",
            "[411] epoch  loss: 0.34738072752952576\n",
            "0.9411764705882353\n",
            "[412] epoch  loss: 0.3473658561706543\n",
            "0.9411764705882353\n",
            "[413] epoch  loss: 0.3473510146141052\n",
            "0.9411764705882353\n",
            "[414] epoch  loss: 0.34733596444129944\n",
            "0.9411764705882353\n",
            "[415] epoch  loss: 0.34732118248939514\n",
            "0.9411764705882353\n",
            "[416] epoch  loss: 0.34730616211891174\n",
            "0.9411764705882353\n",
            "[417] epoch  loss: 0.34729117155075073\n",
            "0.9411764705882353\n",
            "[418] epoch  loss: 0.34727635979652405\n",
            "0.9411764705882353\n",
            "[419] epoch  loss: 0.34726130962371826\n",
            "0.9411764705882353\n",
            "[420] epoch  loss: 0.34724611043930054\n",
            "0.9411764705882353\n",
            "[421] epoch  loss: 0.34723106026649475\n",
            "0.9411764705882353\n",
            "[422] epoch  loss: 0.34721606969833374\n",
            "0.9411764705882353\n",
            "[423] epoch  loss: 0.34720104932785034\n",
            "0.9411764705882353\n",
            "[424] epoch  loss: 0.3471858501434326\n",
            "0.9411764705882353\n",
            "[425] epoch  loss: 0.34717074036598206\n",
            "0.9411764705882353\n",
            "[426] epoch  loss: 0.3471555709838867\n",
            "0.9411764705882353\n",
            "[427] epoch  loss: 0.34714022278785706\n",
            "0.9117647058823529\n",
            "[428] epoch  loss: 0.3471248745918274\n",
            "0.9117647058823529\n",
            "[429] epoch  loss: 0.34710973501205444\n",
            "0.9117647058823529\n",
            "[430] epoch  loss: 0.3470943570137024\n",
            "0.9117647058823529\n",
            "[431] epoch  loss: 0.3470790386199951\n",
            "0.9117647058823529\n",
            "[432] epoch  loss: 0.34706369042396545\n",
            "0.9117647058823529\n",
            "[433] epoch  loss: 0.34704843163490295\n",
            "0.9117647058823529\n",
            "[434] epoch  loss: 0.34703293442726135\n",
            "0.9117647058823529\n",
            "[435] epoch  loss: 0.3470175862312317\n",
            "0.9117647058823529\n",
            "[436] epoch  loss: 0.3470020294189453\n",
            "0.9117647058823529\n",
            "[437] epoch  loss: 0.3469865322113037\n",
            "0.9117647058823529\n",
            "[438] epoch  loss: 0.3469710648059845\n",
            "0.9117647058823529\n",
            "[439] epoch  loss: 0.3469555675983429\n",
            "0.9117647058823529\n",
            "[440] epoch  loss: 0.34694012999534607\n",
            "0.9117647058823529\n",
            "[441] epoch  loss: 0.34692442417144775\n",
            "0.9117647058823529\n",
            "[442] epoch  loss: 0.34690892696380615\n",
            "0.9117647058823529\n",
            "[443] epoch  loss: 0.34689322113990784\n",
            "0.9117647058823529\n",
            "[444] epoch  loss: 0.3468775153160095\n",
            "0.9117647058823529\n",
            "[445] epoch  loss: 0.3468618392944336\n",
            "0.9117647058823529\n",
            "[446] epoch  loss: 0.34684619307518005\n",
            "0.9117647058823529\n",
            "[447] epoch  loss: 0.3468303084373474\n",
            "0.9117647058823529\n",
            "[448] epoch  loss: 0.34681466221809387\n",
            "0.9117647058823529\n",
            "[449] epoch  loss: 0.34679871797561646\n",
            "0.9117647058823529\n",
            "[450] epoch  loss: 0.3467830419540405\n",
            "0.9117647058823529\n",
            "[451] epoch  loss: 0.3467671871185303\n",
            "0.9117647058823529\n",
            "[452] epoch  loss: 0.3467513620853424\n",
            "0.9117647058823529\n",
            "[453] epoch  loss: 0.34673547744750977\n",
            "0.9117647058823529\n",
            "[454] epoch  loss: 0.34671953320503235\n",
            "0.9117647058823529\n",
            "[455] epoch  loss: 0.3467036783695221\n",
            "0.9117647058823529\n",
            "[456] epoch  loss: 0.3466876149177551\n",
            "0.9117647058823529\n",
            "[457] epoch  loss: 0.34667161107063293\n",
            "0.9117647058823529\n",
            "[458] epoch  loss: 0.34665563702583313\n",
            "0.9117647058823529\n",
            "[459] epoch  loss: 0.3466397225856781\n",
            "0.9117647058823529\n",
            "[460] epoch  loss: 0.3466235399246216\n",
            "0.9411764705882353\n",
            "[461] epoch  loss: 0.346607506275177\n",
            "0.9411764705882353\n",
            "[462] epoch  loss: 0.3465912938117981\n",
            "0.9411764705882353\n",
            "[463] epoch  loss: 0.34657514095306396\n",
            "0.9411764705882353\n",
            "[464] epoch  loss: 0.3465590476989746\n",
            "0.9411764705882353\n",
            "[465] epoch  loss: 0.34654295444488525\n",
            "0.9411764705882353\n",
            "[466] epoch  loss: 0.3465266227722168\n",
            "0.9411764705882353\n",
            "[467] epoch  loss: 0.3465104401111603\n",
            "0.9411764705882353\n",
            "[468] epoch  loss: 0.34649407863616943\n",
            "0.9411764705882353\n",
            "[469] epoch  loss: 0.3464779853820801\n",
            "0.9411764705882353\n",
            "[470] epoch  loss: 0.3464617133140564\n",
            "0.9411764705882353\n",
            "[471] epoch  loss: 0.3464452028274536\n",
            "0.9117647058823529\n",
            "[472] epoch  loss: 0.3464289605617523\n",
            "0.9117647058823529\n",
            "[473] epoch  loss: 0.3464125096797943\n",
            "0.9117647058823529\n",
            "[474] epoch  loss: 0.34639590978622437\n",
            "0.9117647058823529\n",
            "[475] epoch  loss: 0.34637951850891113\n",
            "0.9117647058823529\n",
            "[476] epoch  loss: 0.34636324644088745\n",
            "0.9117647058823529\n",
            "[477] epoch  loss: 0.34634673595428467\n",
            "0.9117647058823529\n",
            "[478] epoch  loss: 0.34633031487464905\n",
            "0.9117647058823529\n",
            "[479] epoch  loss: 0.3463136851787567\n",
            "0.9117647058823529\n",
            "[480] epoch  loss: 0.34629717469215393\n",
            "0.9117647058823529\n",
            "[481] epoch  loss: 0.34628039598464966\n",
            "0.9117647058823529\n",
            "[482] epoch  loss: 0.34626391530036926\n",
            "0.9117647058823529\n",
            "[483] epoch  loss: 0.34624722599983215\n",
            "0.9117647058823529\n",
            "[484] epoch  loss: 0.34623053669929504\n",
            "0.9117647058823529\n",
            "[485] epoch  loss: 0.3462136387825012\n",
            "0.9117647058823529\n",
            "[486] epoch  loss: 0.3461969494819641\n",
            "0.9117647058823529\n",
            "[487] epoch  loss: 0.3461802005767822\n",
            "0.9117647058823529\n",
            "[488] epoch  loss: 0.3461635410785675\n",
            "0.9117647058823529\n",
            "[489] epoch  loss: 0.34614670276641846\n",
            "0.9117647058823529\n",
            "[490] epoch  loss: 0.3461299240589142\n",
            "0.9117647058823529\n",
            "[491] epoch  loss: 0.346112996339798\n",
            "0.9117647058823529\n",
            "[492] epoch  loss: 0.34609606862068176\n",
            "0.9117647058823529\n",
            "[493] epoch  loss: 0.34607917070388794\n",
            "0.9117647058823529\n",
            "[494] epoch  loss: 0.3460623621940613\n",
            "0.9117647058823529\n",
            "[495] epoch  loss: 0.34604525566101074\n",
            "0.9117647058823529\n",
            "[496] epoch  loss: 0.34602829813957214\n",
            "0.9117647058823529\n",
            "[497] epoch  loss: 0.34601128101348877\n",
            "0.9117647058823529\n",
            "[498] epoch  loss: 0.3459942042827606\n",
            "0.9117647058823529\n",
            "[499] epoch  loss: 0.34597718715667725\n",
            "0.9117647058823529\n",
            "\n",
            "\n",
            "Best Accuracy:0.9411764705882353% in Epoch 374 outputtensor([[-6.9572e-01, -6.9059e-01],\n",
            "        [-6.9462e-01, -6.9168e-01],\n",
            "        [-6.8790e-01, -6.9842e-01],\n",
            "        [-6.4361e-01, -7.4527e-01],\n",
            "        [-6.2834e-01, -7.6244e-01],\n",
            "        [-6.6266e-01, -7.2459e-01],\n",
            "        [-2.7425e-01, -1.4277e+00],\n",
            "        [-3.0239e-01, -1.3434e+00],\n",
            "        [-6.7034e-01, -7.1649e-01],\n",
            "        [-7.3445e-01, -6.5349e-01],\n",
            "        [-2.3763e-02, -3.7515e+00],\n",
            "        [-1.5296e-01, -1.9531e+00],\n",
            "        [-2.1877e-01, -1.6271e+00],\n",
            "        [-6.6083e-01, -7.2655e-01],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-2.7195e-01, -1.4350e+00],\n",
            "        [-1.7812e-01, -1.8130e+00],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-6.9256e-01, -6.9373e-01],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-1.7812e-01, -1.8130e+00],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-7.0559e-01, -6.8086e-01],\n",
            "        [-7.1243e-01, -6.7423e-01],\n",
            "        [-8.4979e-01, -5.5775e-01],\n",
            "        [-7.2391e-01, -6.6330e-01],\n",
            "        [-8.3604e-01, -5.6814e-01],\n",
            "        [-7.0982e-01, -6.7675e-01],\n",
            "        [-8.0075e-01, -5.9600e-01],\n",
            "        [-6.9715e-01, -6.8917e-01],\n",
            "        [-9.3309e-01, -4.9978e-01],\n",
            "        [-1.7541e+00, -1.9002e-01],\n",
            "        [-9.4339e+00, -8.0109e-05]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOYxuiIhaEFN",
        "colab_type": "code",
        "outputId": "30136313-7462-4bb0-bbe3-50ea772b7e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import imageio,os\n",
        "files = list(map(lambda x:str(x)+'.png', list(range(0,250))))\n",
        "print(files)\n",
        "images = []\n",
        "#filenames=sorted((fn for fn in os.listdir('.') if fn.endswith('.png')))\n",
        "files = list(map(lambda x:str(x)+'.png', list(range(0,450))))\n",
        "print(files)\n",
        "for filename in files:\n",
        "    images.append(imageio.imread(filename))\n",
        "#imageio.mimsave('gif.gif', images,duration=1)\n",
        "imageio.mimsave('result.gif', images,fps=25)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0.png', '1.png', '2.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png', '100.png', '101.png', '102.png', '103.png', '104.png', '105.png', '106.png', '107.png', '108.png', '109.png', '110.png', '111.png', '112.png', '113.png', '114.png', '115.png', '116.png', '117.png', '118.png', '119.png', '120.png', '121.png', '122.png', '123.png', '124.png', '125.png', '126.png', '127.png', '128.png', '129.png', '130.png', '131.png', '132.png', '133.png', '134.png', '135.png', '136.png', '137.png', '138.png', '139.png', '140.png', '141.png', '142.png', '143.png', '144.png', '145.png', '146.png', '147.png', '148.png', '149.png', '150.png', '151.png', '152.png', '153.png', '154.png', '155.png', '156.png', '157.png', '158.png', '159.png', '160.png', '161.png', '162.png', '163.png', '164.png', '165.png', '166.png', '167.png', '168.png', '169.png', '170.png', '171.png', '172.png', '173.png', '174.png', '175.png', '176.png', '177.png', '178.png', '179.png', '180.png', '181.png', '182.png', '183.png', '184.png', '185.png', '186.png', '187.png', '188.png', '189.png', '190.png', '191.png', '192.png', '193.png', '194.png', '195.png', '196.png', '197.png', '198.png', '199.png', '200.png', '201.png', '202.png', '203.png', '204.png', '205.png', '206.png', '207.png', '208.png', '209.png', '210.png', '211.png', '212.png', '213.png', '214.png', '215.png', '216.png', '217.png', '218.png', '219.png', '220.png', '221.png', '222.png', '223.png', '224.png', '225.png', '226.png', '227.png', '228.png', '229.png', '230.png', '231.png', '232.png', '233.png', '234.png', '235.png', '236.png', '237.png', '238.png', '239.png', '240.png', '241.png', '242.png', '243.png', '244.png', '245.png', '246.png', '247.png', '248.png', '249.png', '250.png', '251.png', '252.png', '253.png', '254.png', '255.png', '256.png', '257.png', '258.png', '259.png', '260.png', '261.png', '262.png', '263.png', '264.png', '265.png', '266.png', '267.png', '268.png', '269.png', '270.png', '271.png', '272.png', '273.png', '274.png', '275.png', '276.png', '277.png', '278.png', '279.png', '280.png', '281.png', '282.png', '283.png', '284.png', '285.png', '286.png', '287.png', '288.png', '289.png', '290.png', '291.png', '292.png', '293.png', '294.png', '295.png', '296.png', '297.png', '298.png', '299.png', '300.png', '301.png', '302.png', '303.png', '304.png', '305.png', '306.png', '307.png', '308.png', '309.png', '310.png', '311.png', '312.png', '313.png', '314.png', '315.png', '316.png', '317.png', '318.png', '319.png', '320.png', '321.png', '322.png', '323.png', '324.png', '325.png', '326.png', '327.png', '328.png', '329.png', '330.png', '331.png', '332.png', '333.png', '334.png', '335.png', '336.png', '337.png', '338.png', '339.png', '340.png', '341.png', '342.png', '343.png', '344.png', '345.png', '346.png', '347.png', '348.png', '349.png', '350.png', '351.png', '352.png', '353.png', '354.png', '355.png', '356.png', '357.png', '358.png', '359.png', '360.png', '361.png', '362.png', '363.png', '364.png', '365.png', '366.png', '367.png', '368.png', '369.png', '370.png', '371.png', '372.png', '373.png', '374.png', '375.png', '376.png', '377.png', '378.png', '379.png', '380.png', '381.png', '382.png', '383.png', '384.png', '385.png', '386.png', '387.png', '388.png', '389.png', '390.png', '391.png', '392.png', '393.png', '394.png', '395.png', '396.png', '397.png', '398.png', '399.png', '400.png', '401.png', '402.png', '403.png', '404.png', '405.png', '406.png', '407.png', '408.png', '409.png', '410.png', '411.png', '412.png', '413.png', '414.png', '415.png', '416.png', '417.png', '418.png', '419.png', '420.png', '421.png', '422.png', '423.png', '424.png', '425.png', '426.png', '427.png', '428.png', '429.png', '430.png', '431.png', '432.png', '433.png', '434.png', '435.png', '436.png', '437.png', '438.png', '439.png', '440.png', '441.png', '442.png', '443.png', '444.png', '445.png', '446.png', '447.png', '448.png', '449.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYW-ti36HrDJ",
        "colab_type": "text"
      },
      "source": [
        "![Vis](result.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhUZvv_8BGBy",
        "colab_type": "text"
      },
      "source": [
        "后面的代码没用了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRPM_5m95Z7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "def zip_files( files, zip_name ):\n",
        "    zip = zipfile.ZipFile( zip_name, 'w', zipfile.ZIP_DEFLATED )\n",
        "    print ('compressing')\n",
        "    for file in files:\n",
        "        zip.write( file )\n",
        "    zip.close()\n",
        "    print ('compressing finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhawtmwYXij4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = list(map(lambda x:str(x)+'.png', list(range(0,250))))\n",
        "print(files)\n",
        "zip_files(files,'GCN_plot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qpg0U8-Y6VN",
        "colab_type": "code",
        "outputId": "17f95f91-3636-4a71-9c65-086eb4532d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import imageio\n",
        "\n",
        "outfilename = \"output.gif\" # 转化的GIF图片名称\n",
        "filenames = []\n",
        "for i in range(100):\n",
        "    filename = str(i)+'.png'\n",
        "    filenames.append(filename)\n",
        "frames = []\n",
        "for image_name in filenames:\n",
        "    im = imageio.read(image_name)           # 读取方式上存在略微区别，由于是直接读取数据，并不需要后续处理\n",
        "    frames.append(im)\n",
        "imageio.mimsave(outfilename, frames, 'GIF', duration=0.1) # 生成方式也差不多"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-6bdcf09a1007>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# 读取方式上存在略微区别，由于是直接读取数据，并不需要后续处理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GIF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 生成方式也差不多\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image must be 2D \"\u001b[0m \u001b[0;34m\"(grayscale, RGB, or RGBA).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image must be a numpy array.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;31m# Add image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Image must be a numpy array."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLjiIOJXZeG6",
        "colab_type": "code",
        "outputId": "8f85751f-ded6-475c-bbcf-57d2c4370b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "!pip install images2gif\n",
        "from PIL import Image \n",
        "from images2gif import writeGif\n",
        "outfilename = \"my.gif\" # 转化的GIF图片名称           \n",
        "filenames = []         # 存储所需要读取的图片名称\n",
        "for i in range(100):   # 读取100张图片\n",
        "    filename = str(i)+'.png'   # path是图片所在文件，最后filename的名字必须是存在的图片 \n",
        "    filenames.append(filename)              # 将使用的读取图片汇总\n",
        "frames = []\n",
        "for image_name in filenames:                # 索引各自目录\n",
        "    im = Image.open(image_name)             # 将图片打开，本文图片读取的结果是RGBA格式，如果直接读取的RGB则不需要下面那一步\n",
        "    im = im.convert(\"RGB\")                  # 通过convert将RGBA格式转化为RGB格式，以便后续处理 \n",
        "    im = np.array(im)                       # im还不是数组格式，通过此方法将im转化为数组\n",
        "    frames.append(im)                       # 批量化\n",
        "writeGif(outfilename, frames, duration=0.1, subRectangles=False) # 生成GIF，其中durantion是延迟，这里是1ms"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-797bafdc77e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimages2gif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriteGif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"my.gif\"\u001b[0m \u001b[0;31m# 转化的GIF图片名称\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m         \u001b[0;31m# 存储所需要读取的图片名称\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# 读取100张图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/images2gif/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimages2gif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreadGif\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreadGif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimages2gif\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwriteGif\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwriteGif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'readGif'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvx6Ap4hZiE_",
        "colab_type": "code",
        "outputId": "e7e14e16-c12f-4142-baee-ffcb488f6178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}