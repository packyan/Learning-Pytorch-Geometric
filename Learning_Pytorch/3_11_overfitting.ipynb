{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型选择 欠拟合 过拟合\n",
    "\n",
    "## 训练误差 和 泛化误差 \n",
    "\n",
    "我们需要区分训练误差（training error）和泛化误差（generalization error）。通俗来讲，前者指模型在训练数据集上表现出的误差，后者指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似\n",
    "\n",
    "### 比如高考这个任务，你训练的是往年真题，训练集，测试的是今年的题目，测试集，往年的题目你做得再好，也不一定代表今年的成绩。\n",
    "\n",
    "### 机器学习里的一个假设，就是训练集与测试集都是再同一个概率分布中相互独立生成的，符合独立同分布假设。\n",
    "\n",
    "训练误差的期望小于或等于泛化误差。也就是说，一般情况下，由训练数据集学到的模型参数会使模型在训练数据集上的表现优于或等于在测试数据集上的表现。由于无法从训练误差估计泛化误差，一味地降低训练误差并不意味着泛化误差一定会降低。\n",
    "\n",
    "## 模型选择\n",
    "\n",
    "模型的设计，比如多少层，每层的超参是多少。\n",
    "\n",
    "### 验证集\n",
    "\n",
    "测试集的数据，在训练的时候一般是不能用来训练的，这里有一个transductive learing 与 inductive learing 的问题。\n",
    "\n",
    "一般来说的学习 是 指 Inductive learning， 测试集作为未见类，不能用来训练，你装作这个东西不存在，不去碰。\n",
    "\n",
    "用了这个东西，就不叫inductive learning了，transductive 一般比inductive效果好。\n",
    "\n",
    "### 既然不能从测试集中进行参数的调优，那怎么调呢？ 利用验证集\n",
    "\n",
    "我们可以预留一部分在训练数据集和测试数据集以外的数据来进行模型选择。这部分数据被称为验证数据集，简称验证集（validation set）。\n",
    "\n",
    "**我们可以从给定的训练集中随机选取一小部分作为验证集，而将剩余部分作为真正的训练集。**\n",
    "\n",
    "### k折交叉验证\n",
    "\n",
    "一种改善的方法是$K$折交叉验证（$K$-fold cross-validation）。在$K$折交叉验证中，我们把原始训练数据集分割成$K$个不重合的子数据集，然后我们做$K$次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他$K-1$个子数据集来训练模型。\n",
    "\n",
    "然后对k此训练误差和验证误差求平均。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  欠拟合和过拟合\n",
    "\n",
    "一类是模型无法得到较低的训练误差，我们将这一现象称作欠拟合（underfitting）；另一类是模型的训练误差远小于它在测试数据集上的误差，我们称该现象为过拟合（overfitting）。\n",
    "\n",
    "\n",
    "## 模型复杂度\n",
    "\n",
    "\n",
    "给定训练数据集，如果模型的复杂度过低，很容易出现欠拟合；如果模型复杂度过高，很容易出现过拟合。\n",
    "\n",
    "欠拟合： 模型的复杂度太小， 原来是二次曲线的，只用一个线性模型，是没办法拟合的。\n",
    "\n",
    "模型复杂度如果很高，过拟合就会把一条直线，拟合成 一条 七扭八歪的 曲线。\n",
    "\n",
    "如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。\n",
    "\n",
    "\n",
    "训练数据越多，是件好事。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "- 由于无法从训练误差估计泛化误差，一味地降低训练误差并不意味着泛化误差一定会降低。机器学习模型应关注降低泛化误差。\n",
    "- 可以使用验证数据集来进行模型选择。\n",
    "- 欠拟合指模型无法得到较低的训练误差，过拟合指模型的训练误差远小于它在测试数据集上的误差。\n",
    "- 应选择复杂度合适的模型并避免使用过少的训练样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
